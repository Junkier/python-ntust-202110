{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2e6bff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PTT 股票版 \n",
    "\n",
    "### 取得首頁 source code\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "url = \"https://www.ptt.cc/bbs/Stock/index.html\"\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res = requests.get(url,headers=headers)\n",
    "soup = bs(res.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "82c92fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/Stock/M.1636447699.A.10E.html [標的] 康普、美琪瑪\n",
      "https://www.ptt.cc/bbs/Stock/M.1636447991.A.83A.html [情報] 力積電10月合併營收 61.65億 月增\n",
      "https://www.ptt.cc/bbs/Stock/M.1636448546.A.881.html [情報] 3017 奇鋐 110年10月營收40.32億、年增15.49%\n",
      "https://www.ptt.cc/bbs/Stock/M.1636449650.A.C24.html [新聞] 解封效益顯現 街口投信：股市、油市樂觀\n",
      "https://www.ptt.cc/bbs/Stock/M.1636450580.A.B7F.html [情報] 2615萬海 Q3\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451024.A.198.html [情報] 三晃(1721)-11010-營業收入資訊\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451065.A.179.html [新聞] NVIDIA 推出人工智慧虛擬化身平台\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451180.A.BF7.html [情報] 3545 敦泰10月營收\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451227.A.9E7.html [情報] 華南金(2880) 10月自結\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451480.A.524.html [其他]永豐大戶投神奇開戶歷程（黑特）\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451503.A.7C2.html [情報] 6509聚和 Q1Q2Q3\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451968.A.57E.html [新聞] 光洋科經營權之爭 馬堅勇爆料：台積電高度關切\n",
      "https://www.ptt.cc/bbs/Stock/M.1636453704.A.10B.html [情報] 1109 分點重壓股\n",
      "https://www.ptt.cc/bbs/Stock/M.1636453784.A.2F5.html [新聞] 深圳一貨輪沉沒 70貨櫃漂浮水上航線暫停\n"
     ]
    }
   ],
   "source": [
    "### 抓取首頁文章連結\n",
    "links = []\n",
    "for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "    \n",
    "    # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "    title = a_tag.text\n",
    "    \n",
    "    if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "        continue # 跳過此步, 執行下一動迴圈\n",
    "    else:\n",
    "        url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "        print(url,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e5de3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/Stock/index5002.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index5001.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index5000.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4999.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4998.html is ok.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "### 抓取 分頁文章 連結\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    # 建構 '上頁' 連結\n",
    "    link = soup.select(\"div#action-bar-container div.btn-group-paging a\")[1][\"href\"]\n",
    "    previous_link = \"https://www.ptt.cc\" + link\n",
    "\n",
    "    res = requests.get(previous_link,headers=headers)\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "\n",
    "    for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "\n",
    "        # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "        title = a_tag.text\n",
    "\n",
    "        if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "            continue # 跳過此步, 執行下一動迴圈\n",
    "        else:\n",
    "            url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "            links.append(url)\n",
    "            \n",
    "    print(\"{} is ok.\".format(previous_link))\n",
    "        \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2339bc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec38d2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/Stock/M.1636446231.A.ACE.html\n"
     ]
    }
   ],
   "source": [
    "### 抓取文章本文 source code \n",
    "url = links[11]\n",
    "print(url)\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res2 = requests.get(url,headers=headers)\n",
    "soup2 = bs(res2.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0332c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author : centaurjr (魔術師)\n",
      "category : Stock\n",
      "title : [新聞] 威剛第3季獲利銳減97.6% DRAM現貨價下跌\n",
      "time : Tue Nov  9 16:23:49 2021\n"
     ]
    }
   ],
   "source": [
    "### 抓取本文的 作者 , 看板 , 標題 , 時間 \n",
    "span_tags = soup2.select(\"div#main-content span.article-meta-value\")\n",
    "\n",
    "# 作者\n",
    "author = span_tags[0].text\n",
    "print(\"author :\",author)\n",
    "\n",
    "# 看板\n",
    "category = span_tags[1].text\n",
    "print(\"category :\",category)\n",
    "\n",
    "# 標題\n",
    "title = span_tags[2].text\n",
    "print(\"title :\",title)\n",
    "\n",
    "# 時間\n",
    "time = span_tags[3].text\n",
    "print(\"time :\",time)\n",
    "\n",
    "# span_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5cf18950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 抓取本文的 內容 , 回應\n",
    "# 標籤拔除 --> .extract()\n",
    "# 為了標籤拔除 , 故先抓取 回應資料\n",
    "\n",
    "# push_tags = soup2.select(\"div#main-content div.push\")\n",
    "\n",
    "# 抓其中一項做測試\n",
    "# ele = push_tags[77]\n",
    "# span_tags = ele.select(\"span\")\n",
    "\n",
    "# resp = {\n",
    "#     \"tag\"     : span_tags[0].text.strip(),\n",
    "#     \"author\"  : span_tags[1].text.strip(),\n",
    "#     \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "#     \"time\"    : span_tags[3].text.strip()\n",
    "# }\n",
    "# print(resp)\n",
    "# span_tags\n",
    "\n",
    "#############\n",
    "# for-loop 處理全部回應\n",
    "# resp_data = []\n",
    "\n",
    "# for ele in push_tags:\n",
    "#     span_tags = ele.select(\"span\")\n",
    "\n",
    "#     resp = {\n",
    "#         \"tag\"     : span_tags[0].text.strip(),\n",
    "#         \"author\"  : span_tags[1].text.strip(),\n",
    "#         \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "#         \"time\"    : span_tags[3].text.strip()\n",
    "#     }\n",
    "    \n",
    "#     resp_data.append(resp)\n",
    "    \n",
    "#############\n",
    "# 加入拔除標籤動作\n",
    "def get_resp_data(ele):\n",
    "    span_tags = ele.select(\"span\")\n",
    "    return {\n",
    "        \"tag\"     : span_tags[0].text.strip(),\n",
    "        \"author\"  : span_tags[1].text.strip(),\n",
    "        \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "        \"time\"    : span_tags[3].text.strip()\n",
    "    }\n",
    "\n",
    "\n",
    "push_tags = soup2.select(\"div#main-content div.push\")\n",
    "resp_data = []\n",
    "\n",
    "if len(push_tags) >0:\n",
    "    \n",
    "    for ele in push_tags:\n",
    "        ele.extract()  # 宣告從 div#main-content 中,拔除 div.push 標籤\n",
    "        \n",
    "        resp = get_resp_data(ele)\n",
    "        \n",
    "        resp_data.append(resp)\n",
    "        \n",
    "#         span_tags = ele.select(\"span\")\n",
    "        \n",
    "#         resp = {\n",
    "#             \"tag\"     : span_tags[0].text.strip(),\n",
    "#             \"author\"  : span_tags[1].text.strip(),\n",
    "#             \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "#             \"time\"    : span_tags[3].text.strip()\n",
    "#         }\n",
    "\n",
    "    \n",
    "# print(resp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5ef3fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: 原文標題： 威剛第3季獲利銳減97.6% DRAM現貨價下跌影響\n",
      "\n",
      "原文連結： https://reurl.cc/6DelXk\n",
      "\n",
      "發布時間： 2021年11月9日 週二 下午3:58\n",
      "\n",
      "\n",
      "原文內容：\n",
      "\n",
      "（中央社記者張建中新竹2021年11月9日電）動態隨機存取記憶體（DRAM）現貨價下跌，\n",
      "衝擊記憶體模組廠威剛 (3260) 第3季獲利表現，歸屬母公司淨利新台幣3514萬元，季減\n",
      "97.6%，每股純益0.14元。\n",
      "\n",
      "威剛董事會今天通過第3季財報，季營收96.84億元，較第2季減少8.9%，毛利率10.5%，較\n",
      "第2季下滑7.7個百分點，歸屬母公司淨利3514萬元，季減97.6%，每股純益0.14元。\n",
      "\n",
      "威剛表示，DRAM現貨價格下跌，是影響第3季毛利率及獲利下滑的主因。\n",
      "\n",
      "據威剛公布財報數字，前3季營收294.11億元，為歷年同期次高水準，年增25.89%，毛利\n",
      "率維持16%水準，歸屬母公司淨利21.94億元，年增逾1倍，每股純益9.03元。\n",
      "\n",
      "展望未來，威剛表示，DRAM上游庫存狀況相當穩定健康，預期第4季DRAM價格跌幅應有限\n",
      "，毛利率可望回升。\n",
      "\n",
      "\n",
      "心得/評論：                             ※必需填寫滿20字\n",
      "\n",
      "營收嚇死人,獲利笑死人\n",
      "\n",
      "明天應該沒有電梯向哪邊的問題吧?\n",
      "\n",
      "先猜跳空5%往下\n",
      "\n",
      "\n",
      "--\n",
      "\n",
      "Q2 營業利益 1,033\n",
      "   業外收支   874\n",
      "\n",
      "腰斬再腰斬我可以理解,但是2.4% ??\n"
     ]
    }
   ],
   "source": [
    "### 內容\n",
    "# print(soup2.select(\"div#main-content\")[0].text)\n",
    "\n",
    "# 1. 移除標籤\n",
    "# - div.article-metaline\n",
    "# - div.article-metaline-right\n",
    "# - span.f2\n",
    "\n",
    "def remove_dirty_tag(soup):\n",
    "    \n",
    "    # 若存在 , 則移除標籤\n",
    "    if len(soup.select(\"div.article-metaline\")) >0 :\n",
    "        \n",
    "        # 標籤可能多項 , 使用 for-loop 移除\n",
    "        for tag in soup.select(\"div.article-metaline\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"div.article-metaline-right\")) >0 :\n",
    "        for tag in soup.select(\"div.article-metaline-right\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"span.f2\")) >0 :\n",
    "        for tag in soup.select(\"span.f2\"):\n",
    "            tag.extract()\n",
    "    \n",
    "    return soup \n",
    "\n",
    "\n",
    "\n",
    "soup2 = remove_dirty_tag(soup2)\n",
    "\n",
    "# 2. 抓取文字\n",
    "content = soup2.select(\"div#main-content\")[0].text.strip()\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "128cfb1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 取得本文 source code 完成！\n",
      "* 抓取首頁文章連結 完成！\n",
      "https://www.ptt.cc/bbs/Stock/index5003.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index5002.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index5001.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index5000.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4999.html is ok.\n",
      "* 抓取分頁文章連結 完成！\n",
      "https://www.ptt.cc/bbs/Stock/M.1636457095.A.C50.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636457180.A.1E8.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636447699.A.10E.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636447991.A.83A.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636448546.A.881.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636449650.A.C24.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636450580.A.B7F.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451024.A.198.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451065.A.179.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451180.A.BF7.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451227.A.9E7.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451480.A.524.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451503.A.7C2.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636451968.A.57E.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636453704.A.10B.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636453784.A.2F5.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636455450.A.B93.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636455904.A.1F4.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636457035.A.E6E.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636441843.A.440.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636442247.A.D57.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636442358.A.233.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636442556.A.EA2.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636442751.A.CAC.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636443428.A.87A.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636443429.A.004.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636443634.A.CA0.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636444541.A.A62.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636444634.A.24C.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1636445190.A.D39.html is ok.\n",
      "* 抓取文章資料 完成！\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "### 組合程式\n",
    "\n",
    "## 引用套件\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "## 定義 function\n",
    "\n",
    "# 移除標籤\n",
    "# - div.article-metaline\n",
    "# - div.article-metaline-right\n",
    "# - span.f2\n",
    "def remove_dirty_tag(soup):\n",
    "    \n",
    "    # 若存在 , 則移除標籤\n",
    "    if len(soup.select(\"div.article-metaline\")) >0 :\n",
    "        \n",
    "        # 標籤可能多項 , 使用 for-loop 移除\n",
    "        for tag in soup.select(\"div.article-metaline\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"div.article-metaline-right\")) >0 :\n",
    "        for tag in soup.select(\"div.article-metaline-right\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"span.f2\")) >0 :\n",
    "        for tag in soup.select(\"span.f2\"):\n",
    "            tag.extract()\n",
    "    \n",
    "    return soup \n",
    "\n",
    "# 回應資料\n",
    "def get_resp_data(ele):\n",
    "    span_tags = ele.select(\"span\")\n",
    "    return {\n",
    "        \"tag\"     : span_tags[0].text.strip(),\n",
    "        \"author\"  : span_tags[1].text.strip(),\n",
    "        \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "        \"time\"    : span_tags[3].text.strip()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data(soup,url):\n",
    "    ### 抓取本文的 作者 , 看板 , 標題 , 時間 \n",
    "    span_tags = soup.select(\"div#main-content span.article-meta-value\")\n",
    "\n",
    "    # 作者\n",
    "    author = span_tags[0].text\n",
    "\n",
    "    # 看板\n",
    "    category = span_tags[1].text\n",
    "\n",
    "    # 標題\n",
    "    title = span_tags[2].text\n",
    "\n",
    "    # 時間\n",
    "    time = span_tags[3].text\n",
    "\n",
    "    ### 抓取本文的 內容 , 回應\n",
    "    push_tags = soup.select(\"div#main-content div.push\")\n",
    "    resp_data = []\n",
    "\n",
    "    if len(push_tags) >0:\n",
    "\n",
    "        for ele in push_tags:\n",
    "            ele.extract()  # 宣告從 div#main-content 中,拔除 div.push 標籤\n",
    "\n",
    "            resp = get_resp_data(ele)\n",
    "\n",
    "            resp_data.append(resp)\n",
    "\n",
    "    ### 內容\n",
    "    soup = remove_dirty_tag(soup)\n",
    "    content = soup.select(\"div#main-content\")[0].text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"author\" : author,\n",
    "        \"category\" : category,\n",
    "        \"title\" : title,\n",
    "        \"time\" : time,\n",
    "        \"resp_data\" : resp_data,\n",
    "        \"content\" : content,\n",
    "        \"url\"     : url   # 新增連結欄位\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "## main 程式\n",
    "\n",
    "## 取得本文 source code\n",
    "url = \"https://www.ptt.cc/bbs/Stock/index.html\"\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res = requests.get(url,headers=headers)\n",
    "soup = bs(res.text,\"lxml\")\n",
    "\n",
    "links = []\n",
    "\n",
    "print(\"* 取得本文 source code 完成！\")\n",
    "\n",
    "\n",
    "### 抓取首頁文章連結\n",
    "for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "    \n",
    "    # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "    title = a_tag.text\n",
    "    \n",
    "    if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "        continue # 跳過此步, 執行下一動迴圈\n",
    "    else:\n",
    "        url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "        links.append(url)\n",
    "        \n",
    "print(\"* 抓取首頁文章連結 完成！\")\n",
    "\n",
    "        \n",
    "### 抓取 分頁文章 連結\n",
    "for i in range(1,6):\n",
    "    \n",
    "    # 建構 '上頁' 連結\n",
    "    link = soup.select(\"div#action-bar-container div.btn-group-paging a\")[1][\"href\"]\n",
    "    previous_link = \"https://www.ptt.cc\" + link\n",
    "\n",
    "    res = requests.get(previous_link,headers=headers)\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "\n",
    "    for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "\n",
    "        # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "        title = a_tag.text\n",
    "\n",
    "        if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "            continue # 跳過此步, 執行下一動迴圈\n",
    "        else:\n",
    "            url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "            links.append(url)\n",
    "            \n",
    "    print(\"{} is ok.\".format(previous_link))\n",
    "\n",
    "print(\"* 抓取分頁文章連結 完成！\")\n",
    "\n",
    "\n",
    "### 抓取文章本文 source code + 清理資料\n",
    "\n",
    "# url = links[11]\n",
    "\n",
    "dataList = []\n",
    "for url in links[:30]:      ### 教學用 , 先限定10筆\n",
    "    res2 = requests.get(url,headers=headers)\n",
    "    soup2 = bs(res2.text,\"lxml\")\n",
    "\n",
    "    # 透過 get_data 從 soup2 解析出 dict 資料\n",
    "    data = get_data(soup2,url)\n",
    "    dataList.append(data)\n",
    "\n",
    "    print(\"{} is ok.\".format(url))\n",
    "    \n",
    "print(\"* 抓取文章資料 完成！\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c827be3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(dataList))\n",
    "# dataList[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbac679",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dict 快速複製\n",
    "## Mac -> command\n",
    "## Window -> Ctrl\n",
    "# author\n",
    "# category\n",
    "# title\n",
    "# time\n",
    "\n",
    "# {\n",
    "#     \"author\" : author,\n",
    "#     \"category\" : category,\n",
    "#     \"title\" : title,\n",
    "#     \"time\" : time,\n",
    "#     \"resp_data\" : resp_data,\n",
    "#     \"content\" : content,\n",
    "#     \"url\"     : url   # 新增連結欄位\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "43c64364",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 資料落地\n",
    "import os\n",
    "\n",
    "# data = dataList[3]\n",
    "# print(data)\n",
    "\n",
    "# 檢查 sample 資料夾是否存在\n",
    "# 不存在 -> 新建一個資料夾\n",
    "if not os.path.exists(\"sample\"):\n",
    "    os.mkdir(\"sample\")\n",
    "    \n",
    "for data in dataList:\n",
    "\n",
    "    with open(\"sample/{}.txt\".format(data[\"title\"]),\"w\") as out_file:\n",
    "\n",
    "        records = \"\"\n",
    "\n",
    "        for key in data:\n",
    "            if key == \"resp_data\":\n",
    "                continue\n",
    "\n",
    "            # records 併接\n",
    "            records += \"{} : {}\\n\".format(key ,data[key])\n",
    "\n",
    "        records += \"=\"*80\n",
    "        records += \"\\n\"\n",
    "\n",
    "        # 回應處理\n",
    "        resp = \"\"\n",
    "\n",
    "        for ele in data[\"resp_data\"]:\n",
    "            resp += \"{},{},{},{}\\n\".format(ele[\"tag\"],ele[\"author\"],ele[\"content\"],ele[\"time\"])\n",
    "\n",
    "        records += resp\n",
    "\n",
    "        out_file.write(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "51425a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b9a0c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"resp_data\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
